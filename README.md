# ğŸ‡§ğŸ‡· Engine de AnÃ¡lise de Sentimentos Multi-Idioma

![Status do Projeto](https://img.shields.io/badge/Status-Ativo-brightgreen)
![VersÃ£o](https://img.shields.io/badge/VersÃ£o-1.0.0-blue)
![LicenÃ§a](https://img.shields.io/badge/LicenÃ§a-MIT-green)
![Linguagens](https://img.shields.io/badge/Linguagens-Python%20|%20Kafka%20|%20FastAPI-orange)

Um engine de anÃ¡lise de sentimentos de alta performance e escalÃ¡vel, capaz de processar texto em mais de 100 idiomas em tempo real. Este projeto utiliza modelos transformer state-of-the-art (BERT, XLM-RoBERTa) e uma arquitetura de microsserviÃ§os orientada a eventos para fornecer anÃ¡lise de sentimentos precisa e com baixa latÃªncia.

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Funcionalidades](#funcionalidades)
- [Tecnologias Utilizadas](#tecnologias-utilizadas)
- [Arquitetura](#arquitetura)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Uso](#uso)
- [Modelos](#modelos)
- [APIs](#apis)
- [Streaming](#streaming)
- [Monitoramento](#monitoramento)
- [Exemplos](#exemplos)
- [ContribuiÃ§Ã£o](#contribuiÃ§Ã£o)
- [LicenÃ§a](#licenÃ§a)
- [Contato](#contato)

## ğŸ” VisÃ£o Geral

Este projeto implementa um engine de anÃ¡lise de sentimentos multi-idioma projetado para aplicaÃ§Ãµes de larga escala e tempo real. O sistema Ã© capaz de processar grandes volumes de texto de diversas fontes (mÃ­dias sociais, notÃ­cias, reviews) em mais de 100 idiomas, fornecendo insights valiosos sobre a opiniÃ£o pÃºblica, reputaÃ§Ã£o de marca e tendÃªncias de mercado.

A arquitetura Ã© baseada em microsserviÃ§os e utiliza Apache Kafka para comunicaÃ§Ã£o assÃ­ncrona e processamento de streaming. Modelos transformer prÃ©-treinados e fine-tuned sÃ£o utilizados para garantir alta precisÃ£o na anÃ¡lise de sentimentos, incluindo nuances como sarcasmo e anÃ¡lise baseada em aspectos.

## âœ¨ Funcionalidades

- **AnÃ¡lise Multi-Idioma**: Suporte para mais de 100 idiomas utilizando modelos como XLM-RoBERTa.
- **Modelos Transformer**: UtilizaÃ§Ã£o de modelos state-of-the-art (BERT, RoBERTa, XLM-R) para alta precisÃ£o.
- **Processamento em Tempo Real**: Arquitetura de streaming com Kafka para anÃ¡lise de baixa latÃªncia (<50ms).
- **Alta Escalabilidade**: Projetado para processar milhares de requisiÃ§Ãµes por segundo.
- **AnÃ¡lise AvanÃ§ada**: DetecÃ§Ã£o de emoÃ§Ãµes, anÃ¡lise baseada em aspectos (Aspect-Based Sentiment Analysis - ABSA), detecÃ§Ã£o de sarcasmo.
- **APIs FlexÃ­veis**: Endpoints REST, GraphQL e gRPC para integraÃ§Ã£o.
- **Monitoramento Completo**: MÃ©tricas de performance, detecÃ§Ã£o de drift de modelo, logs centralizados.
- **Treinamento e Fine-tuning**: Pipelines para fine-tuning de modelos em domÃ­nios especÃ­ficos.

## ğŸ› ï¸ Tecnologias Utilizadas

### Linguagens de ProgramaÃ§Ã£o
- **Python**: Linguagem principal para desenvolvimento dos modelos e APIs.

### Frameworks e Bibliotecas
- **Transformers (Hugging Face)**: Para carregar e utilizar modelos prÃ©-treinados.
- **TensorFlow/PyTorch**: Backend para os modelos transformer.
- **FastAPI**: Framework para construÃ§Ã£o das APIs REST.
- **Strawberry (GraphQL)**: Para a API GraphQL.
- **gRPC**: Para comunicaÃ§Ã£o de alta performance entre serviÃ§os.
- **Kafka-Python**: Cliente Kafka para Python.
- **Scikit-learn**: Para prÃ©-processamento e avaliaÃ§Ã£o.
- **NLTK/SpaCy**: Ferramentas de prÃ©-processamento de texto.

### Infraestrutura e Plataformas
- **Apache Kafka**: Plataforma de streaming de eventos.
- **Redis**: Cache para resultados e metadados.
- **Docker/Kubernetes**: ContainerizaÃ§Ã£o e orquestraÃ§Ã£o.
- **Prometheus/Grafana**: Monitoramento de mÃ©tricas.
- **ELK Stack (Elasticsearch, Logstash, Kibana)**: Logging centralizado.
- **MLflow**: Rastreamento de experimentos e gerenciamento de modelos.

## ğŸ—ï¸ Arquitetura

O sistema segue uma arquitetura de microsserviÃ§os orientada a eventos:

1.  **IngestÃ£o de Dados**: Produtores enviam texto para tÃ³picos Kafka (e.g., `social_media_stream`, `news_stream`).
2.  **PrÃ©-processamento**: Um microsserviÃ§o consome os tÃ³picos, realiza a limpeza e tokenizaÃ§Ã£o do texto, e publica em um tÃ³pico `preprocessed_text`.
3.  **AnÃ¡lise de Sentimentos**: MicrosserviÃ§os especializados (um para cada modelo/idioma ou um serviÃ§o multi-modelo) consomem o tÃ³pico `preprocessed_text`, realizam a inferÃªncia e publicam os resultados (sentimento, emoÃ§Ã£o, aspectos) em tÃ³picos como `sentiment_results`.
4.  **AgregaÃ§Ã£o e Armazenamento**: Um serviÃ§o consome os resultados, agrega insights e armazena em um banco de dados (e.g., Elasticsearch, ClickHouse) e/ou cache (Redis).
5.  **APIs**: APIs (REST, GraphQL, gRPC) expÃµem os resultados e funcionalidades para os clientes.
6.  **Monitoramento**: ServiÃ§os de monitoramento coletam mÃ©tricas e logs de todos os componentes.

```mermaid
graph TD
    A[Fontes de Dados] --> B(Produtores Kafka);
    B --> C{TÃ³pico Kafka: Raw Text};
    C --> D[ServiÃ§o de PrÃ©-processamento];
    D --> E{TÃ³pico Kafka: Preprocessed Text};
    E --> F[ServiÃ§o de AnÃ¡lise de Sentimentos];
    F --> G{TÃ³pico Kafka: Sentiment Results};
    G --> H[ServiÃ§o de AgregaÃ§Ã£o/Armazenamento];
    H --> I[(Banco de Dados / Cache)];
    I --> J(APIs: REST/GraphQL/gRPC);
    J --> K[Clientes];
    
    subgraph Monitoramento
        M(Prometheus/Grafana)
        L(ELK Stack)
    end
    
    D --> M;
    F --> M;
    H --> M;
    J --> M;
    D --> L;
    F --> L;
    H --> L;
    J --> L;
```

## ğŸ“ Estrutura do Projeto

```
multi-language-sentiment-engine/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/                # ImplementaÃ§Ã£o dos modelos de sentimento
â”‚   â”œâ”€â”€ api/                   # CÃ³digo das APIs (FastAPI, GraphQL, gRPC)
â”‚   â”œâ”€â”€ data/                  # MÃ³dulos de carregamento e acesso a dados
â”‚   â”œâ”€â”€ preprocessing/         # MÃ³dulos de prÃ©-processamento de texto
â”‚   â”œâ”€â”€ evaluation/            # Scripts para avaliaÃ§Ã£o de modelos
â”‚   â”œâ”€â”€ streaming/             # Consumidores e produtores Kafka
â”‚   â””â”€â”€ visualization/         # MÃ³dulos para dashboards (opcional)
â”œâ”€â”€ scripts/                   # Scripts utilitÃ¡rios (treinamento, deploy)
â”œâ”€â”€ config/                    # Arquivos de configuraÃ§Ã£o
â”œâ”€â”€ data/                      # Dados de exemplo e datasets
â”œâ”€â”€ docs/                      # DocumentaÃ§Ã£o adicional
â”œâ”€â”€ deployment/                # Arquivos de deployment (Dockerfiles, Kubernetes YAMLs)
â”œâ”€â”€ tests/                     # Testes automatizados
â”œâ”€â”€ requirements.txt           # DependÃªncias Python
â””â”€â”€ README.md                  # Este arquivo
```

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos
- Python 3.8+
- Docker e Docker Compose
- Apache Kafka (pode ser executado via Docker Compose)
- Git

### InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/galafis/multi-language-sentiment-engine.git
cd multi-language-sentiment-engine

# Crie um ambiente virtual (recomendado)
python -m venv venv
source venv/bin/activate  # Linux/macOS
# venv\Scripts\activate  # Windows

# Instale as dependÃªncias
pip install -r requirements.txt

# Baixe os modelos prÃ©-treinados (pode levar tempo e espaÃ§o)
python scripts/download_models.py

# Inicie os serviÃ§os dependentes (Kafka, Redis) via Docker Compose
docker-compose up -d kafka redis
```

## ğŸ“Š Uso

### Executando os ServiÃ§os

```bash
# Inicie o serviÃ§o de prÃ©-processamento
python src/streaming/preprocessing_service.py

# Inicie o serviÃ§o de anÃ¡lise de sentimentos
python src/streaming/sentiment_analysis_service.py

# Inicie o serviÃ§o de agregaÃ§Ã£o
python src/streaming/aggregation_service.py

# Inicie a API (exemplo com FastAPI)
cd src/api
uvicorn rest_api:app --reload --port 8000
```

### Enviando Texto para AnÃ¡lise (via Kafka)

```python
# Exemplo de produtor Kafka
from kafka import KafkaProducer
import json

producer = KafkaProducer(bootstrap_servers="localhost:9092",
                         value_serializer=lambda v: json.dumps(v).encode("utf-8"))

data = {
    "id": "tweet_123",
    "text": "This is a great product! Highly recommended.",
    "lang": "en",
    "timestamp": "2025-06-05T10:00:00Z"
}

producer.send("raw_text_en", value=data)
producer.flush()
```

### Consultando a API

```bash
# Exemplo com curl (API REST)
curl -X POST "http://localhost:8000/analyze" \
     -H "Content-Type: application/json" \
     -d 
```json
{
  "text": "Ce produit est incroyable!",
  "lang": "fr"
}
```

## ğŸ§  Modelos

O engine suporta diversos modelos transformer:

- **BERT (base, large, multilingual)**: Bom desempenho geral.
- **RoBERTa (base, large)**: Otimizado sobre o BERT.
- **XLM-RoBERTa (base, large)**: Modelo multi-idioma state-of-the-art.
- **Modelos especÃ­ficos de domÃ­nio**: Fine-tuned para finanÃ§as (FinBERT), saÃºde, etc.
- **Modelos especÃ­ficos de idioma**: Treinados para idiomas especÃ­ficos para maior precisÃ£o.

O serviÃ§o de anÃ¡lise seleciona o modelo mais apropriado com base no idioma detectado ou especificado.

## ğŸŒ APIs

- **REST API (FastAPI)**: Endpoint `/analyze` para anÃ¡lise sÃ­ncrona, endpoints para consulta de resultados agregados.
- **GraphQL API (Strawberry)**: Schema flexÃ­vel para consultas customizadas de dados de sentimento.
- **gRPC API**: Interface de alta performance para comunicaÃ§Ã£o entre serviÃ§os internos ou clientes que exigem baixa latÃªncia.

## ğŸŒŠ Streaming

- **Apache Kafka**: Utilizado como broker de mensagens para desacoplar os serviÃ§os e permitir processamento assÃ­ncrono e escalÃ¡vel.
- **TÃ³picos Principais**: `raw_text_<lang>`, `preprocessed_text`, `sentiment_results`, `aggregated_insights`.
- **Consumidores**: Implementados com `kafka-python`, com lÃ³gica de processamento, tratamento de erros e retentativas.

## ğŸ“ˆ Monitoramento

- **MÃ©tricas (Prometheus)**: LatÃªncia de processamento, taxa de transferÃªncia (throughput), utilizaÃ§Ã£o de recursos, contagem de erros.
- **Logs (ELK Stack)**: Logs centralizados de todos os microsserviÃ§os para debugging e auditoria.
- **Tracing (Jaeger/OpenTelemetry)**: Rastreamento de requisiÃ§Ãµes atravÃ©s dos microsserviÃ§os.
- **Monitoramento de Modelo**: DetecÃ§Ã£o de drift de dados e performance do modelo.

## ğŸ“ Exemplos

### AnÃ¡lise de Sentimento de Tweets em Tempo Real

- Um produtor consome a API do Twitter, filtra tweets relevantes e os envia para o tÃ³pico Kafka `raw_text_en`.
- Os serviÃ§os processam os tweets e os resultados sÃ£o visualizados em um dashboard em tempo real.

### AnÃ¡lise de Reviews de Produtos Multi-idioma

- Reviews de e-commerce em diferentes idiomas sÃ£o enviados para os tÃ³picos Kafka correspondentes (`raw_text_fr`, `raw_text_es`, etc.).
- O engine analisa o sentimento geral e por aspecto (preÃ§o, qualidade, entrega) para cada produto.
- RelatÃ³rios agregados sÃ£o gerados para anÃ¡lise de satisfaÃ§Ã£o do cliente.

## ğŸ‘¥ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor, sinta-se Ã  vontade para enviar pull requests, criar issues ou sugerir melhorias.

1. FaÃ§a um fork do projeto
2. Crie sua branch de feature (`git checkout -b feature/amazing-feature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some amazing feature'`)
4. Push para a branch (`git push origin feature/amazing-feature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a licenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ“ Contato

Gabriel Demetrios Lafis - [GitHub](https://github.com/galafis)

Link do projeto: [https://github.com/galafis/multi-language-sentiment-engine](https://github.com/galafis/multi-language-sentiment-engine)

---

# ğŸ‡¬ğŸ‡§ Multi-Language Sentiment Analysis Engine

![Project Status](https://img.shields.io/badge/Status-Active-brightgreen)
![Version](https://img.shields.io/badge/Version-1.0.0-blue)
![License](https://img.shields.io/badge/License-MIT-green)
![Languages](https://img.shields.io/badge/Languages-Python%20|%20Kafka%20|%20FastAPI-orange)

A high-performance and scalable sentiment analysis engine capable of processing text in over 100 languages in real-time. This project utilizes state-of-the-art transformer models (BERT, XLM-RoBERTa) and an event-driven microservices architecture to provide accurate, low-latency sentiment analysis.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Technologies Used](#technologies-used)
- [Architecture](#architecture)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Usage](#usage)
- [Models](#models)
- [APIs](#apis)
- [Streaming](#streaming)
- [Monitoring](#monitoring)
- [Examples](#examples)
- [Contributing](#contributing)
- [License](#license)
- [Contact](#contact)

## ğŸ” Overview

This project implements a multi-language sentiment analysis engine designed for large-scale, real-time applications. The system can process large volumes of text from various sources (social media, news, reviews) in over 100 languages, providing valuable insights into public opinion, brand reputation, and market trends.

The architecture is based on microservices and uses Apache Kafka for asynchronous communication and stream processing. Pre-trained and fine-tuned transformer models are used to ensure high accuracy in sentiment analysis, including nuances like sarcasm and aspect-based analysis.

## âœ¨ Features

- **Multi-Language Analysis**: Support for over 100 languages using models like XLM-RoBERTa.
- **Transformer Models**: Utilization of state-of-the-art models (BERT, RoBERTa, XLM-R) for high accuracy.
- **Real-Time Processing**: Streaming architecture with Kafka for low-latency analysis (<50ms).
- **High Scalability**: Designed to process thousands of requests per second.
- **Advanced Analysis**: Emotion detection, Aspect-Based Sentiment Analysis (ABSA), sarcasm detection.
- **Flexible APIs**: REST, GraphQL, and gRPC endpoints for integration.
- **Comprehensive Monitoring**: Performance metrics, model drift detection, centralized logging.
- **Training and Fine-tuning**: Pipelines for fine-tuning models on specific domains.

## ğŸ› ï¸ Technologies Used

### Programming Languages
- **Python**: Main language for model and API development.

### Frameworks and Libraries
- **Transformers (Hugging Face)**: For loading and using pre-trained models.
- **TensorFlow/PyTorch**: Backend for transformer models.
- **FastAPI**: Framework for building REST APIs.
- **Strawberry (GraphQL)**: For the GraphQL API.
- **gRPC**: For high-performance communication between services.
- **Kafka-Python**: Kafka client for Python.
- **Scikit-learn**: For preprocessing and evaluation.
- **NLTK/SpaCy**: Text preprocessing tools.

### Infrastructure and Platforms
- **Apache Kafka**: Event streaming platform.
- **Redis**: Cache for results and metadata.
- **Docker/Kubernetes**: Containerization and orchestration.
- **Prometheus/Grafana**: Metrics monitoring.
- **ELK Stack (Elasticsearch, Logstash, Kibana)**: Centralized logging.
- **MLflow**: Experiment tracking and model management.

## ğŸ—ï¸ Architecture

The system follows an event-driven microservices architecture:

1.  **Data Ingestion**: Producers send text to Kafka topics (e.g., `social_media_stream`, `news_stream`).
2.  **Preprocessing**: A microservice consumes the topics, performs text cleaning and tokenization, and publishes to a `preprocessed_text` topic.
3.  **Sentiment Analysis**: Specialized microservices (one per model/language or a multi-model service) consume the `preprocessed_text` topic, perform inference, and publish results (sentiment, emotion, aspects) to topics like `sentiment_results`.
4.  **Aggregation and Storage**: A service consumes the results, aggregates insights, and stores them in a database (e.g., Elasticsearch, ClickHouse) and/or cache (Redis).
5.  **APIs**: APIs (REST, GraphQL, gRPC) expose the results and functionalities to clients.
6.  **Monitoring**: Monitoring services collect metrics and logs from all components.

```mermaid
graph TD
    A[Data Sources] --> B(Kafka Producers);
    B --> C{Kafka Topic: Raw Text};
    C --> D[Preprocessing Service];
    D --> E{Kafka Topic: Preprocessed Text};
    E --> F[Sentiment Analysis Service];
    F --> G{Kafka Topic: Sentiment Results};
    G --> H[Aggregation/Storage Service];
    H --> I[(Database / Cache)];
    I --> J(APIs: REST/GraphQL/gRPC);
    J --> K[Clients];
    
    subgraph Monitoring
        M(Prometheus/Grafana)
        L(ELK Stack)
    end
    
    D --> M;
    F --> M;
    H --> M;
    J --> M;
    D --> L;
    F --> L;
    H --> L;
    J --> L;
```

## ğŸ“ Project Structure

```
multi-language-sentiment-engine/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/                # Implementation of sentiment models
â”‚   â”œâ”€â”€ api/                   # API code (FastAPI, GraphQL, gRPC)
â”‚   â”œâ”€â”€ data/                  # Data loading and access modules
â”‚   â”œâ”€â”€ preprocessing/         # Text preprocessing modules
â”‚   â”œâ”€â”€ evaluation/            # Scripts for model evaluation
â”‚   â”œâ”€â”€ streaming/             # Kafka consumers and producers
â”‚   â””â”€â”€ visualization/         # Modules for dashboards (optional)
â”œâ”€â”€ scripts/                   # Utility scripts (training, deployment)
â”œâ”€â”€ config/                    # Configuration files
â”œâ”€â”€ data/                      # Example data and datasets
â”œâ”€â”€ docs/                      # Additional documentation
â”œâ”€â”€ deployment/                # Deployment files (Dockerfiles, Kubernetes YAMLs)
â”œâ”€â”€ tests/                     # Automated tests
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # This file
```

## ğŸš€ Installation

### Prerequisites
- Python 3.8+
- Docker and Docker Compose
- Apache Kafka (can be run via Docker Compose)
- Git

### Installation

```bash
# Clone the repository
git clone https://github.com/galafis/multi-language-sentiment-engine.git
cd multi-language-sentiment-engine

# Create a virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # Linux/macOS
# venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Download pre-trained models (may take time and space)
python scripts/download_models.py

# Start dependent services (Kafka, Redis) via Docker Compose
docker-compose up -d kafka redis
```

## ğŸ“Š Usage

### Running the Services

```bash
# Start the preprocessing service
python src/streaming/preprocessing_service.py

# Start the sentiment analysis service
python src/streaming/sentiment_analysis_service.py

# Start the aggregation service
python src/streaming/aggregation_service.py

# Start the API (example with FastAPI)
cd src/api
uvicorn rest_api:app --reload --port 8000
```

### Sending Text for Analysis (via Kafka)

```python
# Example Kafka producer
from kafka import KafkaProducer
import json

producer = KafkaProducer(bootstrap_servers="localhost:9092",
                         value_serializer=lambda v: json.dumps(v).encode("utf-8"))

data = {
    "id": "tweet_123",
    "text": "This is a great product! Highly recommended.",
    "lang": "en",
    "timestamp": "2025-06-05T10:00:00Z"
}

producer.send("raw_text_en", value=data)
producer.flush()
```

### Querying the API

```bash
# Example with curl (REST API)
curl -X POST "http://localhost:8000/analyze" \
     -H "Content-Type: application/json" \
     -d 
```json
{
  "text": "Ce produit est incroyable!",
  "lang": "fr"
}
```

## ğŸ§  Models

The engine supports various transformer models:

- **BERT (base, large, multilingual)**: Good general performance.
- **RoBERTa (base, large)**: Optimized over BERT.
- **XLM-RoBERTa (base, large)**: State-of-the-art multi-language model.
- **Domain-specific models**: Fine-tuned for finance (FinBERT), healthcare, etc.
- **Language-specific models**: Trained for specific languages for higher accuracy.

The analysis service selects the most appropriate model based on the detected or specified language.

## ğŸŒ APIs

- **REST API (FastAPI)**: `/analyze` endpoint for synchronous analysis, endpoints for querying aggregated results.
- **GraphQL API (Strawberry)**: Flexible schema for custom queries of sentiment data.
- **gRPC API**: High-performance interface for communication between internal services or clients requiring low latency.

## ğŸŒŠ Streaming

- **Apache Kafka**: Used as the message broker to decouple services and enable asynchronous, scalable processing.
- **Main Topics**: `raw_text_<lang>`, `preprocessed_text`, `sentiment_results`, `aggregated_insights`.
- **Consumers**: Implemented with `kafka-python`, including processing logic, error handling, and retries.

## ğŸ“ˆ Monitoring

- **Metrics (Prometheus)**: Processing latency, throughput, resource utilization, error counts.
- **Logs (ELK Stack)**: Centralized logs from all microservices for debugging and auditing.
- **Tracing (Jaeger/OpenTelemetry)**: Request tracing across microservices.
- **Model Monitoring**: Detection of data drift and model performance degradation.

## ğŸ“ Examples

### Real-Time Tweet Sentiment Analysis

- A producer consumes the Twitter API, filters relevant tweets, and sends them to the `raw_text_en` Kafka topic.
- The services process the tweets, and results are visualized on a real-time dashboard.

### Multi-Language Product Review Analysis

- E-commerce reviews in different languages are sent to corresponding Kafka topics (`raw_text_fr`, `raw_text_es`, etc.).
- The engine analyzes overall and aspect-based sentiment (price, quality, delivery) for each product.
- Aggregated reports are generated for customer satisfaction analysis.

## ğŸ‘¥ Contributing

Contributions are welcome! Please feel free to submit pull requests, create issues, or suggest improvements.

1. Fork the project
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“ Contact

Gabriel Demetrios Lafis - [GitHub](https://github.com/galafis)

Project Link: [https://github.com/galafis/multi-language-sentiment-engine](https://github.com/galafis/multi-language-sentiment-engine)

